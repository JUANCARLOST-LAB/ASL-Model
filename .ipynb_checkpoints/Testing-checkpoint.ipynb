{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc421739-1338-41a7-8a5b-72da8d5c0a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import csv\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05941e0f-1b49-47d0-8c88-962f7e5bb864",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_holistic = mp.solutions.holistic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d83a80e-7822-477b-b12f-c1eda38fe1f3",
   "metadata": {},
   "source": [
    "## 1. Without Transformer for Text Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f08ff9-02ca-47ab-8961-0efa51d25efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Flip image\n",
    "        image = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert from bgr 2 rgb\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            row = []\n",
    "            for num, landmark in enumerate(results.left_hand_landmarks.landmark):\n",
    "                row += [landmark.x, landmark.y, landmark.z, landmark.visibility]\n",
    "\n",
    "            row = pd.DataFrame([row])\n",
    "            preds = fit_models['lr'].predict(row)[0]\n",
    "            predict_proba = fit_models['lr'].predict_proba(row)[0]\n",
    "            predict_proba = max(predict_proba)\n",
    "            cv2.rectangle(image, (0,0), (500, 100), (0, 0, 255), -1)\n",
    "            cv2.putText(image, preds, (5, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "            cv2.putText(image, str(round(predict_proba,2)), (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "            \n",
    "        except Exception as error:\n",
    "            pass    \n",
    "\n",
    "\n",
    "        cv2.imshow('ASL', image)\n",
    "        if cv2.waitKey(10) & 0XFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8092fe00-a159-4ed6-9299-9cfb06a8ee3a",
   "metadata": {},
   "source": [
    "## 2. With Transformer for Text Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4d71992-cf44-4a0e-9c66-64c880538dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load nlp library for text correction\n",
    "!pip3 install transformers\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e1610a-42e6-469c-984e-566cd0d38344",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "phrase = \"\"\n",
    "last_letter = None\n",
    "letter_added = False\n",
    "start = time.time()\n",
    "with mp_holistic.Holistic(min_detection_confidence = 0.5, min_tracking_confidence = 0.5) as holistic:\n",
    "    while cap.isOpened():\n",
    "\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Flip image\n",
    "        image = cv2.flip(frame, 1)\n",
    "\n",
    "        # Convert from bgr 2 rgb\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = holistic.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            row = []\n",
    "            for num, landmark in enumerate(results.left_hand_landmarks.landmark):\n",
    "                row += [landmark.x, landmark.y, landmark.z, landmark.visibility]\n",
    "\n",
    "            row = pd.DataFrame([row])\n",
    "            preds = fit_models['lr'].predict(row)[0]\n",
    "            predict_proba = fit_models['lr'].predict_proba(row)[0]\n",
    "            predict_proba = max(predict_proba)\n",
    "            cv2.rectangle(image, (0,0), (500, 100), (0, 0, 255), -1)\n",
    "            cv2.putText(image, preds, (5, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "            cv2.putText(image, str(round(predict_proba,2)), (100, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "            mp_drawing.draw_landmarks(image, results.left_hand_landmarks, mp_holistic.HAND_CONNECTIONS)\n",
    "\n",
    "            if preds == last_letter:\n",
    "                end = time.time()\n",
    "                if end - start > 1:\n",
    "                    phrase += preds\n",
    "                    letter_added = True\n",
    "                    start = end\n",
    "            else:\n",
    "                last_letter = preds\n",
    "                start = time.time()\n",
    "\n",
    "            \n",
    "        except Exception as error:\n",
    "            if last_letter is not None:\n",
    "                last_letter = None\n",
    "                start = time.time()\n",
    "            pass    \n",
    "\n",
    "        cv2.rectangle(image, (700,0), (1600, 100), (0, 0, 255), -1)\n",
    "        if phrase:\n",
    "            phrase = phrase.title()\n",
    "            \n",
    "            if not last_letter and time.time()-start > 2 and letter_added:\n",
    "                letter_added = False\n",
    "                clean_text = fix_spelling(phrase, max_length = 20)\n",
    "                phrase = clean_text[0]['generated_text']\n",
    "                phrase = phrase.replace('.','')\n",
    "                \n",
    "            cv2.putText(image, phrase, (705, 70), cv2.FONT_HERSHEY_SIMPLEX, 2, (255, 255, 255), 3)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        cv2.imshow('ASL', image)\n",
    "        if cv2.waitKey(10) & 0XFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5731f-bbe6-4384-80e8-7c5f74f6f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
